{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from scipy.spatial import distance_matrix\n",
        "import random\n",
        "from sklearn.neighbors import NearestNeighbors\n"
      ],
      "metadata": {
        "id": "JY1dXaAcTgqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = 'content/parkinsons.csv'\n",
        "data = pd.read_csv(data_path)\n"
      ],
      "metadata": {
        "id": "jxFgVv2XTj3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isixpRSsMeAy",
        "outputId": "400461f3-2616-45bb-e73e-033d6645a361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(195, 23)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "JArJj3JXToLo",
        "outputId": "816eef96-e3e4-43fb-949e-e48e778c005d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         1        2        3        4        5        6        7        8  \\\n",
              "0  119.992  157.302   74.997  0.00784  0.00007  0.00370  0.00554  0.01109   \n",
              "1  122.400  148.650  113.819  0.00968  0.00008  0.00465  0.00696  0.01394   \n",
              "2  116.682  131.111  111.555  0.01050  0.00009  0.00544  0.00781  0.01633   \n",
              "3  116.676  137.871  111.366  0.00997  0.00009  0.00502  0.00698  0.01505   \n",
              "4  116.014  141.781  110.655  0.01284  0.00011  0.00655  0.00908  0.01966   \n",
              "\n",
              "         9     10  ...       14       15      16        17        18  \\\n",
              "0  0.04374  0.426  ...  0.06545  0.02211  21.033  0.414783  0.815285   \n",
              "1  0.06134  0.626  ...  0.09403  0.01929  19.085  0.458359  0.819521   \n",
              "2  0.05233  0.482  ...  0.08270  0.01309  20.651  0.429895  0.825288   \n",
              "3  0.05492  0.517  ...  0.08771  0.01353  20.644  0.434969  0.819235   \n",
              "4  0.06425  0.584  ...  0.10470  0.01767  19.649  0.417356  0.823484   \n",
              "\n",
              "         19        20        21        22  label  \n",
              "0 -4.813031  0.266482  2.301442  0.284654      0  \n",
              "1 -4.075192  0.335590  2.486855  0.368674      0  \n",
              "2 -4.443179  0.311173  2.342259  0.332634      0  \n",
              "3 -4.117501  0.334147  2.405554  0.368975      0  \n",
              "4 -3.747787  0.234513  2.332180  0.410335      0  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cbf8d096-679f-4fed-9ca5-1b99468b938f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>119.992</td>\n",
              "      <td>157.302</td>\n",
              "      <td>74.997</td>\n",
              "      <td>0.00784</td>\n",
              "      <td>0.00007</td>\n",
              "      <td>0.00370</td>\n",
              "      <td>0.00554</td>\n",
              "      <td>0.01109</td>\n",
              "      <td>0.04374</td>\n",
              "      <td>0.426</td>\n",
              "      <td>...</td>\n",
              "      <td>0.06545</td>\n",
              "      <td>0.02211</td>\n",
              "      <td>21.033</td>\n",
              "      <td>0.414783</td>\n",
              "      <td>0.815285</td>\n",
              "      <td>-4.813031</td>\n",
              "      <td>0.266482</td>\n",
              "      <td>2.301442</td>\n",
              "      <td>0.284654</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>122.400</td>\n",
              "      <td>148.650</td>\n",
              "      <td>113.819</td>\n",
              "      <td>0.00968</td>\n",
              "      <td>0.00008</td>\n",
              "      <td>0.00465</td>\n",
              "      <td>0.00696</td>\n",
              "      <td>0.01394</td>\n",
              "      <td>0.06134</td>\n",
              "      <td>0.626</td>\n",
              "      <td>...</td>\n",
              "      <td>0.09403</td>\n",
              "      <td>0.01929</td>\n",
              "      <td>19.085</td>\n",
              "      <td>0.458359</td>\n",
              "      <td>0.819521</td>\n",
              "      <td>-4.075192</td>\n",
              "      <td>0.335590</td>\n",
              "      <td>2.486855</td>\n",
              "      <td>0.368674</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>116.682</td>\n",
              "      <td>131.111</td>\n",
              "      <td>111.555</td>\n",
              "      <td>0.01050</td>\n",
              "      <td>0.00009</td>\n",
              "      <td>0.00544</td>\n",
              "      <td>0.00781</td>\n",
              "      <td>0.01633</td>\n",
              "      <td>0.05233</td>\n",
              "      <td>0.482</td>\n",
              "      <td>...</td>\n",
              "      <td>0.08270</td>\n",
              "      <td>0.01309</td>\n",
              "      <td>20.651</td>\n",
              "      <td>0.429895</td>\n",
              "      <td>0.825288</td>\n",
              "      <td>-4.443179</td>\n",
              "      <td>0.311173</td>\n",
              "      <td>2.342259</td>\n",
              "      <td>0.332634</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>116.676</td>\n",
              "      <td>137.871</td>\n",
              "      <td>111.366</td>\n",
              "      <td>0.00997</td>\n",
              "      <td>0.00009</td>\n",
              "      <td>0.00502</td>\n",
              "      <td>0.00698</td>\n",
              "      <td>0.01505</td>\n",
              "      <td>0.05492</td>\n",
              "      <td>0.517</td>\n",
              "      <td>...</td>\n",
              "      <td>0.08771</td>\n",
              "      <td>0.01353</td>\n",
              "      <td>20.644</td>\n",
              "      <td>0.434969</td>\n",
              "      <td>0.819235</td>\n",
              "      <td>-4.117501</td>\n",
              "      <td>0.334147</td>\n",
              "      <td>2.405554</td>\n",
              "      <td>0.368975</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>116.014</td>\n",
              "      <td>141.781</td>\n",
              "      <td>110.655</td>\n",
              "      <td>0.01284</td>\n",
              "      <td>0.00011</td>\n",
              "      <td>0.00655</td>\n",
              "      <td>0.00908</td>\n",
              "      <td>0.01966</td>\n",
              "      <td>0.06425</td>\n",
              "      <td>0.584</td>\n",
              "      <td>...</td>\n",
              "      <td>0.10470</td>\n",
              "      <td>0.01767</td>\n",
              "      <td>19.649</td>\n",
              "      <td>0.417356</td>\n",
              "      <td>0.823484</td>\n",
              "      <td>-3.747787</td>\n",
              "      <td>0.234513</td>\n",
              "      <td>2.332180</td>\n",
              "      <td>0.410335</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbf8d096-679f-4fed-9ca5-1b99468b938f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cbf8d096-679f-4fed-9ca5-1b99468b938f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cbf8d096-679f-4fed-9ca5-1b99468b938f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a7aaa0d5-7f54-479b-8c31-187fb360f992\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a7aaa0d5-7f54-479b-8c31-187fb360f992')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a7aaa0d5-7f54-479b-8c31-187fb360f992 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_counts = data['label'].value_counts()\n",
        "label_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWil5o27Tx-w",
        "outputId": "bca7e503-03e2-4358-e14d-d09a4fc0ec47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "0    147\n",
              "1     48\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = data.isnull().sum()\n",
        "missing_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lprGSfYjULbG",
        "outputId": "7119a223-baef-434e-b10c-e9be751a17ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1        0\n",
              "2        0\n",
              "3        0\n",
              "4        0\n",
              "5        0\n",
              "6        0\n",
              "7        0\n",
              "8        0\n",
              "9        0\n",
              "10       0\n",
              "11       0\n",
              "12       0\n",
              "13       0\n",
              "14       0\n",
              "15       0\n",
              "16       0\n",
              "17       0\n",
              "18       0\n",
              "19       0\n",
              "20       0\n",
              "21       0\n",
              "22       0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "majority_label = label_counts.idxmax()\n",
        "minority_label = label_counts.idxmin()"
      ],
      "metadata": {
        "id": "WRhu3HcxUR4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "majority_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yO7PVSXUXax",
        "outputId": "21bd7f41-0378-4e8c-c244-268943ab3ba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "minority_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0KDGowKUg4h",
        "outputId": "40e801b0-5d9c-41d4-aeaa-c6e53cb28f41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "majority_class = data[data['label'] == majority_label].iloc[:, :-1].values\n",
        "minority_class = data[data['label'] == minority_label].iloc[:, :-1].values\n",
        "labels_majority = data[data['label'] == majority_label]['label'].values\n",
        "labels_minority = data[data['label'] == minority_label]['label'].values"
      ],
      "metadata": {
        "id": "9o8D43R9Um-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "majority_class[:25]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvLhlWa9Utp6",
        "outputId": "7b06a3df-ecd7-44cb-b75f-bfad6c68e150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.199920e+02,  1.573020e+02,  7.499700e+01,  7.840000e-03,\n",
              "         7.000000e-05,  3.700000e-03,  5.540000e-03,  1.109000e-02,\n",
              "         4.374000e-02,  4.260000e-01,  2.182000e-02,  3.130000e-02,\n",
              "         2.971000e-02,  6.545000e-02,  2.211000e-02,  2.103300e+01,\n",
              "         4.147830e-01,  8.152850e-01, -4.813031e+00,  2.664820e-01,\n",
              "         2.301442e+00,  2.846540e-01],\n",
              "       [ 1.224000e+02,  1.486500e+02,  1.138190e+02,  9.680000e-03,\n",
              "         8.000000e-05,  4.650000e-03,  6.960000e-03,  1.394000e-02,\n",
              "         6.134000e-02,  6.260000e-01,  3.134000e-02,  4.518000e-02,\n",
              "         4.368000e-02,  9.403000e-02,  1.929000e-02,  1.908500e+01,\n",
              "         4.583590e-01,  8.195210e-01, -4.075192e+00,  3.355900e-01,\n",
              "         2.486855e+00,  3.686740e-01],\n",
              "       [ 1.166820e+02,  1.311110e+02,  1.115550e+02,  1.050000e-02,\n",
              "         9.000000e-05,  5.440000e-03,  7.810000e-03,  1.633000e-02,\n",
              "         5.233000e-02,  4.820000e-01,  2.757000e-02,  3.858000e-02,\n",
              "         3.590000e-02,  8.270000e-02,  1.309000e-02,  2.065100e+01,\n",
              "         4.298950e-01,  8.252880e-01, -4.443179e+00,  3.111730e-01,\n",
              "         2.342259e+00,  3.326340e-01],\n",
              "       [ 1.166760e+02,  1.378710e+02,  1.113660e+02,  9.970000e-03,\n",
              "         9.000000e-05,  5.020000e-03,  6.980000e-03,  1.505000e-02,\n",
              "         5.492000e-02,  5.170000e-01,  2.924000e-02,  4.005000e-02,\n",
              "         3.772000e-02,  8.771000e-02,  1.353000e-02,  2.064400e+01,\n",
              "         4.349690e-01,  8.192350e-01, -4.117501e+00,  3.341470e-01,\n",
              "         2.405554e+00,  3.689750e-01],\n",
              "       [ 1.160140e+02,  1.417810e+02,  1.106550e+02,  1.284000e-02,\n",
              "         1.100000e-04,  6.550000e-03,  9.080000e-03,  1.966000e-02,\n",
              "         6.425000e-02,  5.840000e-01,  3.490000e-02,  4.825000e-02,\n",
              "         4.465000e-02,  1.047000e-01,  1.767000e-02,  1.964900e+01,\n",
              "         4.173560e-01,  8.234840e-01, -3.747787e+00,  2.345130e-01,\n",
              "         2.332180e+00,  4.103350e-01],\n",
              "       [ 1.205520e+02,  1.311620e+02,  1.137870e+02,  9.680000e-03,\n",
              "         8.000000e-05,  4.630000e-03,  7.500000e-03,  1.388000e-02,\n",
              "         4.701000e-02,  4.560000e-01,  2.328000e-02,  3.526000e-02,\n",
              "         3.243000e-02,  6.985000e-02,  1.222000e-02,  2.137800e+01,\n",
              "         4.155640e-01,  8.250690e-01, -4.242867e+00,  2.991110e-01,\n",
              "         2.187560e+00,  3.577750e-01],\n",
              "       [ 1.202670e+02,  1.372440e+02,  1.148200e+02,  3.330000e-03,\n",
              "         3.000000e-05,  1.550000e-03,  2.020000e-03,  4.660000e-03,\n",
              "         1.608000e-02,  1.400000e-01,  7.790000e-03,  9.370000e-03,\n",
              "         1.351000e-02,  2.337000e-02,  6.070000e-03,  2.488600e+01,\n",
              "         5.960400e-01,  7.641120e-01, -5.634322e+00,  2.576820e-01,\n",
              "         1.854785e+00,  2.117560e-01],\n",
              "       [ 1.073320e+02,  1.138400e+02,  1.043150e+02,  2.900000e-03,\n",
              "         3.000000e-05,  1.440000e-03,  1.820000e-03,  4.310000e-03,\n",
              "         1.567000e-02,  1.340000e-01,  8.290000e-03,  9.460000e-03,\n",
              "         1.256000e-02,  2.487000e-02,  3.440000e-03,  2.689200e+01,\n",
              "         6.374200e-01,  7.632620e-01, -6.167603e+00,  1.837210e-01,\n",
              "         2.064693e+00,  1.637550e-01],\n",
              "       [ 9.573000e+01,  1.320680e+02,  9.175400e+01,  5.510000e-03,\n",
              "         6.000000e-05,  2.930000e-03,  3.320000e-03,  8.800000e-03,\n",
              "         2.093000e-02,  1.910000e-01,  1.073000e-02,  1.277000e-02,\n",
              "         1.717000e-02,  3.218000e-02,  1.070000e-02,  2.181200e+01,\n",
              "         6.155510e-01,  7.735870e-01, -5.498678e+00,  3.277690e-01,\n",
              "         2.322511e+00,  2.315710e-01],\n",
              "       [ 9.505600e+01,  1.201030e+02,  9.122600e+01,  5.320000e-03,\n",
              "         6.000000e-05,  2.680000e-03,  3.320000e-03,  8.030000e-03,\n",
              "         2.838000e-02,  2.550000e-01,  1.441000e-02,  1.725000e-02,\n",
              "         2.444000e-02,  4.324000e-02,  1.022000e-02,  2.186200e+01,\n",
              "         5.470370e-01,  7.984630e-01, -5.011879e+00,  3.259960e-01,\n",
              "         2.432792e+00,  2.713620e-01],\n",
              "       [ 8.833300e+01,  1.122400e+02,  8.407200e+01,  5.050000e-03,\n",
              "         6.000000e-05,  2.540000e-03,  3.300000e-03,  7.630000e-03,\n",
              "         2.143000e-02,  1.970000e-01,  1.079000e-02,  1.342000e-02,\n",
              "         1.892000e-02,  3.237000e-02,  1.166000e-02,  2.111800e+01,\n",
              "         6.111370e-01,  7.761560e-01, -5.249770e+00,  3.910020e-01,\n",
              "         2.407313e+00,  2.497400e-01],\n",
              "       [ 9.190400e+01,  1.158710e+02,  8.629200e+01,  5.400000e-03,\n",
              "         6.000000e-05,  2.810000e-03,  3.360000e-03,  8.440000e-03,\n",
              "         2.752000e-02,  2.490000e-01,  1.424000e-02,  1.641000e-02,\n",
              "         2.214000e-02,  4.272000e-02,  1.141000e-02,  2.141400e+01,\n",
              "         5.833900e-01,  7.925200e-01, -4.960234e+00,  3.635660e-01,\n",
              "         2.642476e+00,  2.759310e-01],\n",
              "       [ 1.369260e+02,  1.598660e+02,  1.312760e+02,  2.930000e-03,\n",
              "         2.000000e-05,  1.180000e-03,  1.530000e-03,  3.550000e-03,\n",
              "         1.259000e-02,  1.120000e-01,  6.560000e-03,  7.170000e-03,\n",
              "         1.140000e-02,  1.968000e-02,  5.810000e-03,  2.570300e+01,\n",
              "         4.606000e-01,  6.468460e-01, -6.547148e+00,  1.528130e-01,\n",
              "         2.041277e+00,  1.385120e-01],\n",
              "       [ 1.391730e+02,  1.791390e+02,  7.655600e+01,  3.900000e-03,\n",
              "         3.000000e-05,  1.650000e-03,  2.080000e-03,  4.960000e-03,\n",
              "         1.642000e-02,  1.540000e-01,  7.280000e-03,  9.320000e-03,\n",
              "         1.797000e-02,  2.184000e-02,  1.041000e-02,  2.488900e+01,\n",
              "         4.301660e-01,  6.658330e-01, -5.660217e+00,  2.549890e-01,\n",
              "         2.519422e+00,  1.998890e-01],\n",
              "       [ 1.528450e+02,  1.633050e+02,  7.583600e+01,  2.940000e-03,\n",
              "         2.000000e-05,  1.210000e-03,  1.490000e-03,  3.640000e-03,\n",
              "         1.828000e-02,  1.580000e-01,  1.064000e-02,  9.720000e-03,\n",
              "         1.246000e-02,  3.191000e-02,  6.090000e-03,  2.492200e+01,\n",
              "         4.747910e-01,  6.540270e-01, -6.105098e+00,  2.036530e-01,\n",
              "         2.125618e+00,  1.701000e-01],\n",
              "       [ 1.421670e+02,  2.174550e+02,  8.315900e+01,  3.690000e-03,\n",
              "         3.000000e-05,  1.570000e-03,  2.030000e-03,  4.710000e-03,\n",
              "         1.503000e-02,  1.260000e-01,  7.720000e-03,  8.880000e-03,\n",
              "         1.359000e-02,  2.316000e-02,  8.390000e-03,  2.517500e+01,\n",
              "         5.659240e-01,  6.582450e-01, -5.340115e+00,  2.101850e-01,\n",
              "         2.205546e+00,  2.345890e-01],\n",
              "       [ 1.441880e+02,  3.492590e+02,  8.276400e+01,  5.440000e-03,\n",
              "         4.000000e-05,  2.110000e-03,  2.920000e-03,  6.320000e-03,\n",
              "         2.047000e-02,  1.920000e-01,  9.690000e-03,  1.200000e-02,\n",
              "         2.074000e-02,  2.908000e-02,  1.859000e-02,  2.233300e+01,\n",
              "         5.673800e-01,  6.446920e-01, -5.440040e+00,  2.397640e-01,\n",
              "         2.264501e+00,  2.181640e-01],\n",
              "       [ 1.687780e+02,  2.321810e+02,  7.560300e+01,  7.180000e-03,\n",
              "         4.000000e-05,  2.840000e-03,  3.870000e-03,  8.530000e-03,\n",
              "         3.327000e-02,  3.480000e-01,  1.441000e-02,  1.893000e-02,\n",
              "         3.430000e-02,  4.322000e-02,  2.919000e-02,  2.037600e+01,\n",
              "         6.310990e-01,  6.054170e-01, -2.931070e+00,  4.343260e-01,\n",
              "         3.007463e+00,  4.307880e-01],\n",
              "       [ 1.530460e+02,  1.758290e+02,  6.862300e+01,  7.420000e-03,\n",
              "         5.000000e-05,  3.640000e-03,  4.320000e-03,  1.092000e-02,\n",
              "         5.517000e-02,  5.420000e-01,  2.471000e-02,  3.572000e-02,\n",
              "         5.767000e-02,  7.413000e-02,  3.160000e-02,  1.728000e+01,\n",
              "         6.653180e-01,  7.194670e-01, -3.949079e+00,  3.578700e-01,\n",
              "         3.109010e+00,  3.774290e-01],\n",
              "       [ 1.564050e+02,  1.893980e+02,  1.428220e+02,  7.680000e-03,\n",
              "         5.000000e-05,  3.720000e-03,  3.990000e-03,  1.116000e-02,\n",
              "         3.995000e-02,  3.480000e-01,  1.721000e-02,  2.374000e-02,\n",
              "         4.310000e-02,  5.164000e-02,  3.365000e-02,  1.715300e+01,\n",
              "         6.495540e-01,  6.860800e-01, -4.554466e+00,  3.401760e-01,\n",
              "         2.856676e+00,  3.221110e-01],\n",
              "       [ 1.538480e+02,  1.657380e+02,  6.578200e+01,  8.400000e-03,\n",
              "         5.000000e-05,  4.280000e-03,  4.500000e-03,  1.285000e-02,\n",
              "         3.810000e-02,  3.280000e-01,  1.667000e-02,  2.383000e-02,\n",
              "         4.055000e-02,  5.000000e-02,  3.871000e-02,  1.753600e+01,\n",
              "         6.601250e-01,  7.040870e-01, -4.095442e+00,  2.625640e-01,\n",
              "         2.739710e+00,  3.653910e-01],\n",
              "       [ 1.538800e+02,  1.728600e+02,  7.812800e+01,  4.800000e-03,\n",
              "         3.000000e-05,  2.320000e-03,  2.670000e-03,  6.960000e-03,\n",
              "         4.137000e-02,  3.700000e-01,  2.021000e-02,  2.591000e-02,\n",
              "         4.525000e-02,  6.062000e-02,  1.849000e-02,  1.949300e+01,\n",
              "         6.290170e-01,  6.989510e-01, -5.186960e+00,  2.376220e-01,\n",
              "         2.557536e+00,  2.597650e-01],\n",
              "       [ 1.679300e+02,  1.932210e+02,  7.906800e+01,  4.420000e-03,\n",
              "         3.000000e-05,  2.200000e-03,  2.470000e-03,  6.610000e-03,\n",
              "         4.351000e-02,  3.770000e-01,  2.228000e-02,  2.540000e-02,\n",
              "         4.246000e-02,  6.685000e-02,  1.280000e-02,  2.246800e+01,\n",
              "         6.190600e-01,  6.798340e-01, -4.330956e+00,  2.623840e-01,\n",
              "         2.916777e+00,  2.856950e-01],\n",
              "       [ 1.739170e+02,  1.927350e+02,  8.618000e+01,  4.760000e-03,\n",
              "         3.000000e-05,  2.210000e-03,  2.580000e-03,  6.630000e-03,\n",
              "         4.192000e-02,  3.640000e-01,  2.187000e-02,  2.470000e-02,\n",
              "         3.772000e-02,  6.562000e-02,  1.840000e-02,  2.042200e+01,\n",
              "         5.372640e-01,  6.868940e-01, -5.248776e+00,  2.102790e-01,\n",
              "         2.547508e+00,  2.535560e-01],\n",
              "       [ 1.636560e+02,  2.008410e+02,  7.677900e+01,  7.420000e-03,\n",
              "         5.000000e-05,  3.800000e-03,  3.900000e-03,  1.140000e-02,\n",
              "         1.659000e-02,  1.640000e-01,  7.380000e-03,  9.480000e-03,\n",
              "         1.497000e-02,  2.214000e-02,  1.778000e-02,  2.383100e+01,\n",
              "         3.979370e-01,  7.324790e-01, -5.557447e+00,  2.208900e-01,\n",
              "         2.692176e+00,  2.159610e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "minority_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeEUA_V3Uxm3",
        "outputId": "95a00edd-8367-4642-a254-64c94ebf7b2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.970760e+02, 2.068960e+02, 1.920550e+02, ..., 1.775510e-01,\n",
              "        1.743867e+00, 8.556900e-02],\n",
              "       [1.992280e+02, 2.095120e+02, 1.920910e+02, ..., 1.733190e-01,\n",
              "        2.103106e+00, 6.850100e-02],\n",
              "       [1.983830e+02, 2.152030e+02, 1.931040e+02, ..., 1.751810e-01,\n",
              "        1.512275e+00, 9.632000e-02],\n",
              "       ...,\n",
              "       [1.746880e+02, 2.400050e+02, 7.428700e+01, ..., 1.584530e-01,\n",
              "        2.679772e+00, 1.317280e-01],\n",
              "       [1.987640e+02, 3.969610e+02, 7.490400e+01, ..., 2.074540e-01,\n",
              "        2.138608e+00, 1.233060e-01],\n",
              "       [2.142890e+02, 2.602770e+02, 7.797300e+01, ..., 1.906670e-01,\n",
              "        2.555477e+00, 1.485690e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = data.drop('label', axis=1).values  # Assuming 'label' is your class label column\n",
        "labels = data['label'].values"
      ],
      "metadata": {
        "id": "r49MwwTnKoYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels=np.reshape(labels, newshape=(len(data),1))"
      ],
      "metadata": {
        "id": "qMKi3T4AIbLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ns59-Ro-MWbE",
        "outputId": "bbc6d905-56d4-4917-c43a-2323e1ede963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(195, 22)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "majority_count = len(labels_majority)\n",
        "minority_count = len(labels_minority)"
      ],
      "metadata": {
        "id": "F8LH2aJcB2KG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "majority_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikdgR4hqDQ2d",
        "outputId": "954bb70b-fccd-4125-d5d8-25e48ed302aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "147"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if minority_count > 0:\n",
        "    imbalance_ratio = majority_count / minority_count\n",
        "else:\n",
        "    imbalance_ratio = 0  # To handle cases with no majority class instances\n",
        "print(f\"Imbalance Ratio: {imbalance_ratio:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwDYqjRaB-D3",
        "outputId": "c6491eb3-a317-4209-d9d1-a7e9bbe81224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imbalance Ratio: 3.0625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_size(N, num_min):\n",
        "    p = num_min / N\n",
        "    if p == 0 and N >= 9:\n",
        "        size1 = 0\n",
        "    elif p == 0 or p == 1:\n",
        "        size1 = 1\n",
        "    else:\n",
        "        Z = 1.64\n",
        "        epsilon = 0.05\n",
        "        e = epsilon + np.log(N) / N\n",
        "        x = (Z**2 * p * (1-p)) / (e**2)\n",
        "        size1 = (N * x) / (x + N - 1)\n",
        "    return math.ceil(size1)"
      ],
      "metadata": {
        "id": "rPG52fkfBjZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculated_sample_size = sample_size(majority_count, minority_count)\n",
        "calculated_sample_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs-3lcoLCDmh",
        "outputId": "dab81e9d-8846-4f8f-98b9-03cf8682be04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def calculate_weights(data, labels, k=5):\n",
        "    labels = np.array(labels).flatten()\n",
        "    nbrs = NearestNeighbors(n_neighbors=k+1, algorithm='ball_tree').fit(data)\n",
        "    distances, indices = nbrs.kneighbors(data)\n",
        "\n",
        "    weights = np.zeros(data.shape[0])\n",
        "    for i in range(data.shape[0]):\n",
        "\n",
        "        distances_i = distances[i, 1:]  # ignore the first one because it's the distance to itself\n",
        "        indices_i = indices[i, 1:]\n",
        "        inverse_distances = 1 / (distances_i + 1e-5)\n",
        "\n",
        "        same_class_mask = (labels[indices_i] == labels[i])\n",
        "        different_class_mask = ~same_class_mask\n",
        "\n",
        "        same_class_weights = inverse_distances * same_class_mask\n",
        "        different_class_weights = inverse_distances * different_class_mask\n",
        "\n",
        "        total_same_class_weight = np.sum(same_class_weights)\n",
        "        total_different_class_weight = np.sum(different_class_weights)\n",
        "        total_weight = total_same_class_weight + total_different_class_weight\n",
        "\n",
        "        if total_weight > 0:\n",
        "            complexity_score = total_same_class_weight / total_weight\n",
        "        else:\n",
        "            complexity_score = 0  # Handle cases with no effective neighbors\n",
        "\n",
        "        weights[i] = complexity_score\n",
        "\n",
        "    return weights\n"
      ],
      "metadata": {
        "id": "MzedsmoTDmL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = calculate_weights(features, labels, k=5)"
      ],
      "metadata": {
        "id": "qFr6743_EzCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_EvivFUSA0Z",
        "outputId": "6f485e0b-6ef1-43b9-c97f-9ae016a3d463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(195,)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "majority_weights = weights[labels.flatten() == majority_label]\n",
        "minority_weights = weights[labels.flatten() == minority_label]"
      ],
      "metadata": {
        "id": "gJbN5LasNn7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minority_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3XaQWfoTwf1",
        "outputId": "14fae544-2984-4fa7-befe-93f34585e802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 0.64728821, 0.68444206, 0.78374225,\n",
              "       0.64248574, 0.72807015, 0.7032221 , 0.42478093, 0.56396843,\n",
              "       0.39874132, 1.        , 1.        , 0.71764557, 0.68814714,\n",
              "       1.        , 1.        , 0.        , 1.        , 1.        ,\n",
              "       0.19989978, 0.30374441, 0.51121327, 0.        , 0.23784556,\n",
              "       0.        , 0.23809991, 0.        , 0.17973657, 0.44129808,\n",
              "       0.40272143, 0.18938806, 0.51416573, 0.37084344, 0.28632871,\n",
              "       0.18425742, 0.        , 0.57724861])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "majority_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek2B8T98T3cg",
        "outputId": "c77894e3-52c8-4f8f-e3bc-f4edb54c0a34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       0.57800943, 0.61352969, 0.33966985, 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 0.7624337 , 0.51601672, 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       0.56342666, 1.        , 1.        , 0.83724026, 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 0.90144088,\n",
              "       1.        , 0.83112739, 1.        , 1.        , 0.81648107,\n",
              "       0.82926183, 0.76841388, 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 0.68710032, 0.25237315,\n",
              "       0.67352781, 0.67309447, 0.76444988, 0.72291313, 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 0.82577893, 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 0.85661289, 0.88330563,\n",
              "       1.        , 1.        , 1.        , 0.41581717, 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       0.76190396, 0.74326491, 0.26905605, 0.46670744, 0.671905  ,\n",
              "       0.72403501, 1.        , 0.89917507, 0.92097424, 0.89595321,\n",
              "       0.53824401, 0.89807071, 0.83604591, 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 0.73854647,\n",
              "       0.7329392 , 0.83803014, 0.84608589, 0.81201353, 0.55145039,\n",
              "       0.66162839, 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 0.36147097, 0.22049093, 1.        , 0.71370462,\n",
              "       1.        , 0.1992991 , 1.        , 1.        , 1.        ,\n",
              "       0.59293092, 1.        , 1.        , 1.        , 0.81472943,\n",
              "       0.87461155, 1.        , 0.79918474, 1.        , 0.79497607,\n",
              "       0.38139574, 0.77320216, 1.        , 1.        , 1.        ,\n",
              "       0.82599001, 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "minority_complexity = sum(minority_weights)/len(minority_weights)\n",
        "majority_complexity = sum(majority_weights)/len(majority_weights)\n",
        "print(f\"Minority Class Complexity: {minority_complexity:.4f}\")\n",
        "print(f\"Majority Class Complexity: {majority_complexity:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ey9OVY0SUDy",
        "outputId": "ac062ef2-5a14-4f16-c5f5-29616d93f7b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minority Class Complexity: 0.6171\n",
            "Majority Class Complexity: 0.8862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data Shape:\", data.shape)\n",
        "print(\"Labels Shape:\", labels.shape)\n",
        "print(\"Weights Shape:\", weights.shape)\n",
        "print(\"Majority weights shape: \", majority_weights.shape)\n",
        "print(\"Majority weights shape: \", minority_weights.shape)\n",
        "print(\"Adjusted Labels Shape:\", labels.shape)\n",
        "print(\"Minority class shape: \", minority_class.shape)\n",
        "print(\"Majority class shape: \", majority_class.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFm1vzKgR2t4",
        "outputId": "33fa2abe-01db-46df-8ad4-12f74633717b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Shape: (195, 23)\n",
            "Labels Shape: (195, 1)\n",
            "Weights Shape: (195,)\n",
            "Majority weights shape:  (147,)\n",
            "Majority weights shape:  (48,)\n",
            "Adjusted Labels Shape: (195, 1)\n",
            "Minority class shape:  (48, 22)\n",
            "Majority class shape:  (147, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_population(valid_indices, population_size, individual_size):\n",
        "    \"\"\" Initialize the population with random selections of valid indices. \"\"\"\n",
        "    return [np.random.choice(valid_indices, size=individual_size, replace=False) for _ in range(population_size)]\n",
        "\n",
        "def calculate_fitness(individual, weights):\n",
        "    \"\"\" Fitness is the sum of weights of selected samples. \"\"\"\n",
        "    return np.sum(weights[individual])\n",
        "\n",
        "def select_parents(population, fitnesses, num_parents):\n",
        "    \"\"\" Select parents based on their fitness scores using roulette wheel selection. \"\"\"\n",
        "    total_fitness = np.sum(fitnesses)\n",
        "    probabilities = fitnesses / total_fitness\n",
        "    parents_indices = np.random.choice(range(len(population)), size=num_parents, replace=True, p=probabilities)\n",
        "    return [population[idx] for idx in parents_indices]\n",
        "\n",
        "def crossover(parent1, parent2):\n",
        "    \"\"\" Perform one-point crossover between two parents. \"\"\"\n",
        "    crossover_point = np.random.randint(1, len(parent1))\n",
        "    child1 = np.concatenate([parent1[:crossover_point], parent2[crossover_point:]])\n",
        "    child2 = np.concatenate([parent2[:crossover_point], parent1[crossover_point:]])\n",
        "    return child1, child2\n",
        "\n",
        "def mutate(individual, mutation_rate, valid_indices):\n",
        "    \"\"\" Mutate an individual's genes. \"\"\"\n",
        "    for i in range(len(individual)):\n",
        "        if np.random.rand() < mutation_rate:\n",
        "            individual[i] = np.random.choice(valid_indices)\n",
        "    return individual\n",
        "\n",
        "def genetic_algorithm(features, weights, population_size, individual_size, generations, mutation_rate):\n",
        "    threshold = np.mean(weights)  # Mean weight as threshold to avoid overlap\n",
        "    valid_indices = np.where(weights > threshold)[0]\n",
        "\n",
        "    population = initialize_population(valid_indices, population_size, individual_size)\n",
        "\n",
        "    for _ in range(generations):\n",
        "        fitnesses = [calculate_fitness(ind, weights) for ind in population]\n",
        "        parents = select_parents(population, fitnesses, len(population))\n",
        "\n",
        "        next_population = []\n",
        "        for i in range(0, len(parents), 2):\n",
        "            child1, child2 = crossover(parents[i], parents[(i + 1) % len(parents)])\n",
        "            child1 = mutate(child1, mutation_rate, valid_indices)\n",
        "            child2 = mutate(child2, mutation_rate, valid_indices)\n",
        "            next_population.extend([child1, child2])\n",
        "        population = next_population[:population_size]\n",
        "\n",
        "    final_fitnesses = [calculate_fitness(ind, weights) for ind in population]\n",
        "    best_index = np.argmax(final_fitnesses)\n",
        "    best_individual = population[best_index]\n",
        "    best_individual_fitness = final_fitnesses[best_index]\n",
        "\n",
        "    # Fetch the actual samples corresponding to the best indices\n",
        "    best_samples = features[best_individual]\n",
        "    return best_samples, best_individual_fitness\n",
        "\n",
        "# Parameters for the GA\n",
        "population_size = 50\n",
        "individual_size = calculated_sample_size  # Ensure itâ€™s less than len(valid_indices)\n",
        "generations = 100\n",
        "mutation_rate = 0.05\n",
        "\n",
        "# Run the genetic algorithm\n",
        "best_samples, best_fitness = genetic_algorithm(features, weights, population_size, individual_size, generations, mutation_rate)\n",
        "\n",
        "print(\"Selected Samples (Best Solution):\\n\", best_samples)\n",
        "print(\"Sum of Weights for the Best Solution:\", best_fitness)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEZshZoiamiT",
        "outputId": "417cbc4f-da56-4542-abfb-3d2dae724441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Samples (Best Solution):\n",
            " [[1.739170e+02 1.927350e+02 8.618000e+01 ... 2.102790e-01 2.547508e+00\n",
            "  2.535560e-01]\n",
            " [1.009600e+02 1.100190e+02 9.562800e+01 ... 1.469480e-01 2.428306e+00\n",
            "  2.646660e-01]\n",
            " [2.524550e+02 2.614870e+02 1.827860e+02 ... 2.008730e-01 2.028612e+00\n",
            "  8.639800e-02]\n",
            " ...\n",
            " [1.284510e+02 1.504490e+02 7.563200e+01 ... 3.101630e-01 2.638279e+00\n",
            "  3.568810e-01]\n",
            " [1.504400e+02 1.634410e+02 1.447360e+02 ... 1.832180e-01 2.264226e+00\n",
            "  1.441050e-01]\n",
            " [1.697740e+02 1.917590e+02 1.514510e+02 ... 4.147580e-01 3.413649e+00\n",
            "  4.575330e-01]]\n",
            "Sum of Weights for the Best Solution: 54.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def concatenate_samples(P, N, SetN):\n",
        "    # Ensure all inputs are at least 2D\n",
        "    P = np.atleast_2d(P)\n",
        "    N = np.atleast_2d(N)\n",
        "    SetN = np.atleast_2d(SetN)\n",
        "\n",
        "    # Cartesian product for P: all combinations of P with itself\n",
        "    P_cartesian = np.array([np.concatenate([p1, p2]) for p1 in P for p2 in P])\n",
        "\n",
        "    # Cartesian product for N and SetN: all combinations of N with SetN\n",
        "    N_cartesian = np.array([np.concatenate([n, sn]) for n in N for sn in SetN])\n",
        "\n",
        "    return P_cartesian, N_cartesian"
      ],
      "metadata": {
        "id": "Eyd7bUAVc9PT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_cartesian, N_cartesian = concatenate_samples(minority_class,majority_class, best_samples)\n"
      ],
      "metadata": {
        "id": "pagRd1Podt40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_cartesian"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vctgroFgeMtm",
        "outputId": "205f885a-cfe1-4ea8-bdf3-2f052773dda8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.970760e+02, 2.068960e+02, 1.920550e+02, ..., 1.775510e-01,\n",
              "        1.743867e+00, 8.556900e-02],\n",
              "       [1.970760e+02, 2.068960e+02, 1.920550e+02, ..., 1.733190e-01,\n",
              "        2.103106e+00, 6.850100e-02],\n",
              "       [1.970760e+02, 2.068960e+02, 1.920550e+02, ..., 1.751810e-01,\n",
              "        1.512275e+00, 9.632000e-02],\n",
              "       ...,\n",
              "       [2.142890e+02, 2.602770e+02, 7.797300e+01, ..., 1.584530e-01,\n",
              "        2.679772e+00, 1.317280e-01],\n",
              "       [2.142890e+02, 2.602770e+02, 7.797300e+01, ..., 2.074540e-01,\n",
              "        2.138608e+00, 1.233060e-01],\n",
              "       [2.142890e+02, 2.602770e+02, 7.797300e+01, ..., 1.906670e-01,\n",
              "        2.555477e+00, 1.485690e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N_cartesian.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXE3L3w2eRBS",
        "outputId": "69819d6d-3f4c-4b75-aead-74283a6c7549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7938, 44)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_weights = calculate_weights(np.vstack((P_cartesian, N_cartesian)), np.concatenate([np.zeros(len(P_cartesian)), np.ones(len(N_cartesian))]), k=5)"
      ],
      "metadata": {
        "id": "_5QuGjuEPkYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minority_weights_new = new_weights[:len(P_cartesian)]\n",
        "majority_weights_new = new_weights[len(P_cartesian):]"
      ],
      "metadata": {
        "id": "vScj2_flPtgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minority_weights_new.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcmhiGTNis6a",
        "outputId": "250170a5-c7a5-4442-a6ea-b31716851aab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2304,)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "majority_weights_new.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piwpKqpViwTA",
        "outputId": "56c8a932-042b-4bb5-b2fe-7473f751f15d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7938,)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate complexities based on the weights calculated\n",
        "minority_complexity = np.mean(minority_weights_new)  # Complexity for minority class after concatenation\n",
        "majority_complexity = np.mean(majority_weights_new)  # Complexity for majority class after concatenation\n",
        "\n",
        "print(f\"Minority Class Complexity after Concatenation: {minority_complexity:.4f}\")\n",
        "print(f\"Majority Class Complexity after Concatenation: {majority_complexity:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYvAN0Euhe0u",
        "outputId": "ce9fbd81-4ff6-4670-a7b2-1ae2bd627c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minority Class Complexity after Concatenation: 0.9541\n",
            "Majority Class Complexity after Concatenation: 0.9912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset, SubsetRandomSampler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, roc_curve, precision_recall_curve, roc_auc_score\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple Multi-Layer Perceptron model class that inherits from nn.Module.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_size, device):\n",
        "        super(MLP, self).__init__()\n",
        "        h = 2 * (input_size + output_size) // 3\n",
        "        self.device = device\n",
        "        self.hidden = nn.Linear(input_size, h).to(device)\n",
        "        self.output = nn.Linear(h, output_size).to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.hidden(x))\n",
        "        x = self.output(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def load_data(train_features, train_labels, train_ids, test_ids, batch_size, device):\n",
        "    \"\"\"\n",
        "    Load and create tensor datasets for both training and validation data.\n",
        "    \"\"\"\n",
        "    features_tensor = torch.tensor(train_features, dtype=torch.float32)\n",
        "    labels_tensor = torch.tensor(train_labels, dtype=torch.int64)\n",
        "    dataset = TensorDataset(features_tensor, labels_tensor)\n",
        "\n",
        "    train_subsampler = SubsetRandomSampler(train_ids)\n",
        "    test_subsampler = SubsetRandomSampler(test_ids)\n",
        "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_subsampler)\n",
        "    val_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_subsampler)\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs, Set_N_selection, fold):\n",
        "    \"\"\"\n",
        "    Train the MLP model with the specified parameters.\n",
        "    \"\"\"\n",
        "    best_recall_score = float('-inf')\n",
        "    best_model_path = \"\"\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        all_predictions, all_labels = [], []\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                all_predictions.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "        fold_recall = recall_score(all_labels, all_predictions)\n",
        "    #   fold_f1_score = f1_score(all_labels, all_predictions, average='weighted')\n",
        "        if fold_recall > best_recall_score:\n",
        "            best_recall_score = fold_recall\n",
        "            if Set_N_selection == 'baseline':\n",
        "                best_model_path = f\"model_baseline_fold_{fold+1}.pth\"\n",
        "                torch.save(model.state_dict(), best_model_path)\n",
        "            else:\n",
        "                best_model_path = f\"model_GA_fold_{fold+1}.pth\"\n",
        "                torch.save(model.state_dict(), best_model_path)\n",
        "\n",
        "    model.load_state_dict(torch.load(best_model_path))\n",
        "    model.to(device).eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "def evaluate_model(model, test_loader, criterion, device):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the test dataset.\n",
        "    \"\"\"\n",
        "    test_loss = 0\n",
        "    all_labels, all_predictions, all_probabilities = [], [], []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item() * inputs.size(0)\n",
        "            probabilities = torch.softmax(outputs, dim=1)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_probabilities.extend(probabilities[:, 1].cpu().numpy())  # Assuming binary classification\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    recall = recall_score(all_labels, all_predictions)\n",
        "    f1 = f1_score(all_labels, all_predictions)\n",
        "    gmean = geometric_mean_score(all_labels, all_predictions)\n",
        "    auc_roc = roc_auc_score(all_labels, all_probabilities)\n",
        "\n",
        "    print(f'Test Loss: {test_loss:.4f},'\n",
        "          f' Accuracy: {accuracy:.4f},'\n",
        "          f' Recall: {recall:.4f},'\n",
        "          f' F1 Score: {f1:.4f},'\n",
        "          f' G-Mean: {gmean:.4f},'\n",
        "          f' ROC AUC: {auc_roc:.4f}')\n",
        "    # Calculate and print the confusion matrix\n",
        "    conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "    l = [(all_labels[i], all_predictions[i]) for i in range(len(all_labels))]\n",
        "    print(l)\n",
        "    print(len(all_labels))\n",
        "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "    plot_performance_curves(all_labels, all_probabilities, auc_roc)\n",
        "\n",
        "\n",
        "def plot_performance_curves(labels, probabilities, auc_roc):\n",
        "    \"\"\"\n",
        "    Plot ROC and Precision-Recall curves.\n",
        "    \"\"\"\n",
        "    fpr, tpr, _ = roc_curve(labels, probabilities)\n",
        "    precision, recall, _ = precision_recall_curve(labels, probabilities)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc_roc)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(recall, precision, color='blue', lw=2, label='Precision-Recall curve')\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Precision-Recall Curve')\n",
        "    plt.legend(loc=\"lower left\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def main(train_data, test_data, config, Set_N_selection):\n",
        "    \"\"\"\n",
        "    Main function to run the training and testing of the MLP model.\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_features = train_data.drop('class_label', axis=1).values\n",
        "    train_labels = train_data['class_label'].values\n",
        "    test_features = test_data.drop('class_label', axis=1).values\n",
        "    test_labels = test_data['class_label'].values\n",
        "\n",
        "    # Load Data\n",
        "    k_folds = config['k_folds']\n",
        "    batch_size = config['batch_size']\n",
        "    num_epochs = config['num_epochs']\n",
        "    learning_rate = config['learning_rate']\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=config['random_seed'])\n",
        "    for fold, (train_ids, test_ids) in enumerate(skf.split(train_features, train_labels)):\n",
        "        print(f\"Starting fold {fold+1} of {k_folds}\")\n",
        "        train_loader, val_loader = load_data(train_features, train_labels, train_ids, test_ids, batch_size, device)\n",
        "        model = MLP(train_features.shape[1], len(np.unique(train_labels)), device)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "        model = train_model(model, train_loader, val_loader, criterion,\n",
        "                            optimizer, device, num_epochs, Set_N_selection, fold)\n",
        "\n",
        "    # Test Model\n",
        "    test_features_tensor, test_labels_tensor = (torch.tensor(test_features, dtype=torch.float32),\n",
        "                                                torch.tensor(test_labels, dtype=torch.int64))\n",
        "    test_dataset = TensorDataset(test_features_tensor, test_labels_tensor)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
        "    evaluate_model(model, test_loader, criterion, device)\n",
        "\n",
        "# Run the main function with proper data and configuration settings\n",
        "# main(train_data, test_data, config)"
      ],
      "metadata": {
        "id": "FibNGmmloL1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92lJlI7UaFbS",
        "outputId": "affb40ed-bbbd-4da6-9b31-933e926bc972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2304, 44])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "zByaS1y3arej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset, SubsetRandomSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "P_features = torch.tensor(P_cartesian, dtype=torch.float32)\n",
        "N_features = torch.tensor(N_cartesian, dtype=torch.float32)\n",
        "features_combined = torch.vstack((P_features, N_features))\n",
        "labels_combined = torch.cat((torch.zeros(len(P_cartesian)), torch.ones(len(N_cartesian))))\n",
        "\n",
        "# Split data into train and test sets\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features_combined, labels_combined, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create TensorDatasets\n",
        "train_dataset = TensorDataset(train_features, train_labels)\n",
        "test_dataset = TensorDataset(test_features, test_labels)\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "YLDZxJ1dpQoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, criterion, optimizer, device, num_epochs):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels.long())  # Ensure labels are long type for CE Loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MLP(features_combined.shape[1], 2, device)  # 2 outputs assuming binary classification\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "train_model(model, train_loader, criterion, optimizer, device, num_epochs=50)\n"
      ],
      "metadata": {
        "id": "DBpK2dbrpSov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    all_labels, all_probabilities = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels.long())\n",
        "            test_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            probabilities = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()  # Get probabilities for class 1\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_probabilities.extend(probabilities)\n",
        "\n",
        "    # Convert lists to numpy arrays for metrics calculation\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_probabilities = np.array(all_probabilities)\n",
        "\n",
        "    # Calculate metrics using numpy array\n",
        "    predictions = (all_probabilities > 0.5).astype(int)  # Convert probabilities to 0 or 1 based on threshold\n",
        "    accuracy = accuracy_score(all_labels, predictions)\n",
        "    recall = recall_score(all_labels, predictions)\n",
        "    f1 = f1_score(all_labels, predictions)\n",
        "    gmean = geometric_mean_score(all_labels, predictions)\n",
        "    auc_roc = roc_auc_score(all_labels, all_probabilities)\n",
        "\n",
        "    print(f'Test Loss: {test_loss/len(test_loader.dataset):.4f},'\n",
        "          f' Accuracy: {accuracy:.4f},'\n",
        "          f' Recall: {recall:.4f},'\n",
        "          f' F1 Score: {f1:.4f},'\n",
        "          f' G-Mean: {gmean:.4f},'\n",
        "          f' ROC AUC: {auc_roc:.4f}')\n",
        "\n",
        "evaluate_model(model, test_loader, criterion, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRGqTVzqpW9z",
        "outputId": "3ebd9c14-c018-40c1-dc92-417cd7142257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.1518, Accuracy: 0.9356, Recall: 0.9510, F1 Score: 0.9577, G-Mean: 0.9173, ROC AUC: 0.9836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N_cartesian"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOH2SC-aa4h3",
        "outputId": "ce57ab4e-872d-4e01-f15a-7f49198e6b71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.199920e+02, 1.573020e+02, 7.499700e+01, ..., 2.102790e-01,\n",
              "        2.547508e+00, 2.535560e-01],\n",
              "       [1.199920e+02, 1.573020e+02, 7.499700e+01, ..., 1.469480e-01,\n",
              "        2.428306e+00, 2.646660e-01],\n",
              "       [1.199920e+02, 1.573020e+02, 7.499700e+01, ..., 2.008730e-01,\n",
              "        2.028612e+00, 8.639800e-02],\n",
              "       ...,\n",
              "       [1.498180e+02, 1.634170e+02, 1.447860e+02, ..., 3.101630e-01,\n",
              "        2.638279e+00, 3.568810e-01],\n",
              "       [1.498180e+02, 1.634170e+02, 1.447860e+02, ..., 1.832180e-01,\n",
              "        2.264226e+00, 1.441050e-01],\n",
              "       [1.498180e+02, 1.634170e+02, 1.447860e+02, ..., 4.147580e-01,\n",
              "        3.413649e+00, 4.575330e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TCcl8MhSa4dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "37D8Zi2pa4YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset, SubsetRandomSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "P_features = torch.tensor(P_cartesian, dtype=torch.float32)\n",
        "N_features = torch.tensor(N_cartesian, dtype=torch.float32)\n",
        "features_combined = torch.vstack((P_features, N_features))\n",
        "labels_combined = torch.cat((torch.zeros(len(P_cartesian)), torch.ones(len(N_cartesian))))\n",
        "\n",
        "# Split data into train and test sets\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features_combined, labels_combined, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create TensorDatasets\n",
        "train_dataset = TensorDataset(train_features, train_labels)\n",
        "test_dataset = TensorDataset(test_features, test_labels)\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "3ls_-XaGa2xK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}